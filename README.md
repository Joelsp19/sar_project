# Search and Rescue (SAR) Agent Framework - CSC 581

## Role: Operation Chief Agent

- Create documents to send to search, rescue, and medical teams
- Should be able to create documents for each update (still working on getting this to be better)
- The mission log should be updated dependent on the mission details (some type of impact from the previous mission logs)

## Main methods used

- Essentially we feed some textual data into a gemini model and returns a structured json format
- Obviously the problem with using LLMs to generate text, plans, and reasoning are the hallucinations
- Then we parse the structured json to verify that we get some information
- For updating documents, we also include the mission log data

- For the test cases, I asked LLMs to generate scenarios for me with some update scenarios as well.
- The test cases don't really evaluate the LLMs performance since that is a hard metric to measure.

- Gemini, Claude, and ChatGPT was used to generate a lot of code and test cases.

## How to run

**init**.py has a couple of examples of utilizing the agent. The generated docs are in a folder called `output_docs`.
You can also run the test with `pytest tests/`
It might be helpful to delete the files in output_docs after a run so the number of documents don't increase.

- For now I've left a couple of example markdown docs from running init to give a general idea on the output response.

## Potential improvements

- Seperate the information to be more specific to the knowledge base set up (I stumbled upon the kb after dev so only ended
  up using the mission log). If we can format the data so that we have some terrain information that comes with the data that would be helpful as well.
- Better markdown formatting (just used something generated by ChatGPT and not so bad)
- The reasoning ability to determine what to do based on the information provided is heavily influenced by the input text.
  More detailed information means more detailed responses
- I included in the prompt to leave unknown information on <> but there are some hallucinations. Some responses are more detailed than others. This may be due to the nature of LLMs and is quite hard to fix without additional formatting or knowledge bases to draw from. I also noticed that the results of the same response are different in terms of the docs created and information provided.
- It would be nice to incorportate some GPS data or some type of update of what area has been searched so that we can include in any updates to leaders, more specific areas to target.
- Overall, after creating this agent I think it would be helpful for creating formatted documents to be send out to search leaders with the information and the human leader can edit whatever info is necessary, but there should be some level of validation. The strength would be in the update documents if we can get them to reflect what teams are affected, so we can get these messages out quickly
